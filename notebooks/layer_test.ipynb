{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "#x = x.to_sparse()\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "conv1 = GCNConv(1, 1)\n",
    "\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "out = conv1(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.nn.aggr import Aggregation, MultiAggregation\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor, Size\n",
    "\n",
    "\n",
    "# TODO\n",
    "# what is edge attribute\n",
    "\n",
    "class TestConv(MessagePassing):\n",
    "   \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        aggr: Optional[Union[str, List[str], Aggregation]] = \"max\",\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "\n",
    "        super().__init__(aggr)\n",
    "\n",
    "        # calculate off-set delta x\n",
    "        self.lin_h = nn.Linear(self.in_channels, self.out_channels)\n",
    "        # calculate edge update\n",
    "        self.lin_f = nn.Linear(self.in_channels * 2, self.out_channels)\n",
    "        # calculate final state update\n",
    "        self.lin_g = nn.Sequential(\n",
    "          nn.Linear(self.in_channels, 64),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(64,self.out_channels)\n",
    "        )\n",
    "        # self.lin_g = nn.Linear(self.in_channels, self.out_channels)\n",
    "        #self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_h.reset_parameters()\n",
    "        self.lin_f.reset_parameters()\n",
    "        self.lin_g.reset_parameters()\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        out = self.propagate(edge_index, x=x, pos=pos)\n",
    "        out = self.lin_g(out)\n",
    "        return x + out\n",
    "\n",
    "    def message(self, pos_j, pos_i, x_i, x_j):\n",
    "        delta = self.lin_h(x_i)\n",
    "        e = torch.cat([pos_j - pos_i + delta, x_j], dim=-1)\n",
    "        e = self.lin_f(e)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'reset_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_518209/3679111611.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# conv1 = TestConv(1, 1, aggr=\"max\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_node_features, num_classes)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointGNNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_node_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointGNNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPointGNNConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, hidden_channels, aggr)\u001b[0m\n\u001b[1;32m     50\u001b[0m           \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     '''def reset_parameters(self):\n",
      "\u001b[0;32m~/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch/layers.py\u001b[0m in \u001b[0;36mreset_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     '''def reset_parameters(self):\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         self.lin_g.reset_parameters()'''\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1266\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'reset_parameters'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/nfs/homedirs/bindera/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch/')\n",
    "from models import PointGNN\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "#x = x.to_sparse()\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "\n",
    "# conv1 = TestConv(1, 1, aggr=\"max\")\n",
    "\n",
    "model = PointGNN(1,1)\n",
    "\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "out = model(x, x, edge_index)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat((x,x), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(x, 2, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge Update: https://pytorch-geometric.readthedocs.io/en/latest/_modules/torch_geometric/nn/conv/gat_conv.html#GATConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Union\n",
    "\n",
    "from torch import Tensor\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense.linear import Linear\n",
    "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
    "\n",
    "\n",
    "class GraphConv(MessagePassing):\n",
    "   \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Tuple[int, int]],\n",
    "        out_channels: int,\n",
    "        aggr: str = 'add',\n",
    "        bias: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            in_channels = (in_channels, in_channels)\n",
    "\n",
    "        self.lin_rel = Linear(in_channels[0], out_channels, bias=bias)\n",
    "        self.lin_root = Linear(in_channels[1], out_channels, bias=False)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_rel.reset_parameters()\n",
    "        self.lin_root.reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
    "                edge_weight: OptTensor = None, size: Size = None) -> Tensor:\n",
    "        \"\"\"\"\"\"\n",
    "        if isinstance(x, Tensor):\n",
    "            x: OptPairTensor = (x, x)\n",
    "\n",
    "        # propagate_type: (x: OptPairTensor, edge_weight: OptTensor)\n",
    "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n",
    "                             size=size)\n",
    "        #out = self.lin_rel(out)\n",
    "\n",
    "        print(x[0])\n",
    "        print(x[1])\n",
    "\n",
    "\n",
    "        x_r = x[1]\n",
    "        #if x_r is not None:\n",
    "        #    out = out + self.lin_root(x_r)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def message(self, x_j: Tensor, edge_weight: OptTensor) -> Tensor:\n",
    "        print(edge_weight)\n",
    "        return x_j if edge_weight is None else edge_weight.view(-1, 1) * x_j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n"
     ]
    }
   ],
   "source": [
    "conv1 = GraphConv(1, 1, aggr=\"max\")\n",
    "\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "out = conv1(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.],\n",
       "        [ 0.],\n",
       "        [ 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data is 9843\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_train_1024pts_fps.dat...\n",
      "The size of test data is 2468\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_test_1024pts_fps.dat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1968/1968 [00:45<00:00, 43.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.adversarial_attacks_on_feature_dependent_graphs.dataset import PointCloudDataset\n",
    "from src.adversarial_attacks_on_feature_dependent_graphs.data import *\n",
    "\n",
    "val_dataset_v2 = PointCloudDataset(split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointCloudDataset(1968)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/nfs/students/bindera/data/modelnet_pyg/val_dataset.pt'\n",
    "torch.save(val_dataset_v2, path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test_dataset = torch.load(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/nfs/homedirs/bindera/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/nfs/homedirs/bindera/reference_implementations/Point-GNN-PyTorch/src/point_gnn_pytorch/')\n",
    "from models import PointGNN\n",
    "from layers import PointGNNConv\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "#x = x.to_sparse()\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "\n",
    "#  sample = \n",
    "\n",
    "# conv1 = TestConv(1, 1, aggr=\"max\")\n",
    "\n",
    "#sample = [0]\n",
    "test_dataset\n",
    "data = test_dataset[0]\n",
    "\n",
    "data = Data(x=data.x, edge_index=data.edge_index.t().contiguous(), y=data.y)\n",
    "\n",
    "x, edge_index = data.x, data.edge_index\n",
    "\n",
    "\n",
    "\n",
    "# conv = PointGNNConv(state_channels = 3,\n",
    "#         pos_channels = 3,\n",
    "#         hidden_channels = 64)\n",
    "\n",
    "# out = conv(x, x, edge_index)\n",
    "\n",
    "model = PointGNN(num_node_features = 3, \n",
    "                    num_classes = 5)\n",
    "model_out = model(data)\n",
    "model_out.shape\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "# data = test_dataset[0]\n",
    "\n",
    "# data = Data(x=data.x, edge_index=data.edge_index.t().contiguous(), y=data.y)\n",
    "train_loader = DataLoader(val_dataset_v2, batch_size=16, shuffle=True) \n",
    "data = next(iter(train_loader))\n",
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[4096, 3], edge_index=[2, 131072], y=[4], batch=[4096], ptr=[5])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 5])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 3], edge_index=[32768, 2], y=[1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32768])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index.t().contiguous().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = Data(x=data.x, edge_index=data.edge_index.t().contiguous(), y=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import MLP\n",
    "\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "mlp = MLP([1, 32, 64, 128])\n",
    "\n",
    "mlp(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb.init(project=\"my-test-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.nn import ARMAConv, MLP\n",
    "from torch_geometric.testing import is_full_test\n",
    "\n",
    "from src.adversarial_attacks_on_feature_dependent_graphs.baselines import PointGNNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 64, 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_h = MLP([3, 64, 3])\n",
    "MLP_h.channel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_h = MLP([3, 64, 3])\n",
    "MLP_f = MLP([6, 64, 3])\n",
    "MLP_g = MLP([3, 64, 3])\n",
    "\n",
    "conv = PointGNNConv(state_channels=3, MLP_h=MLP_h, MLP_f=MLP_f, MLP_g=MLP_g)\n",
    "assert conv.__repr__() == 'PointGNNConv(3, lin_h=MLP(3, 64, 3), lin_f=MLP(6, 64, 3),lin_g=MLP(3, 64, 3))'\n",
    "# conv.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nArguments for call are not valid.\nThe following variants are available:\n  \n  propagate__0(__torch__.PointGNNConvJittable_f382d4.PointGNNConvJittable_f382d4 self, Tensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type 'Tensor' for argument 'edge_index' but instead found type 'Union[Tensor, __torch__.torch_sparse.tensor.SparseTensor]'.\n  \n  propagate__1(__torch__.PointGNNConvJittable_f382d4.PointGNNConvJittable_f382d4 self, __torch__.torch_sparse.tensor.SparseTensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type '__torch__.torch_sparse.tensor.SparseTensor (of Python compilation unit at: 0x5028480)' for argument 'edge_index' but instead found type 'Union[Tensor, __torch__.torch_sparse.tensor.SparseTensor]'.\n\nThe original call is:\n  File \"/tmp/bindera_pyg/tmpd9y4phyc.py\", line 238\n        # type: (Tensor, Tensor, Adj) -> Tensor\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n              ~~~~~~~~~~~~~~ <--- HERE\n        out = self.lin_g(out)\n        return x + out\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1039835/4071786133.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(Tensor, Tensor, Adj) -> Tensor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjittable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         return torch.jit._recursive.create_script_module(\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  propagate__0(__torch__.PointGNNConvJittable_f382d4.PointGNNConvJittable_f382d4 self, Tensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type 'Tensor' for argument 'edge_index' but instead found type 'Union[Tensor, __torch__.torch_sparse.tensor.SparseTensor]'.\n  \n  propagate__1(__torch__.PointGNNConvJittable_f382d4.PointGNNConvJittable_f382d4 self, __torch__.torch_sparse.tensor.SparseTensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type '__torch__.torch_sparse.tensor.SparseTensor (of Python compilation unit at: 0x5028480)' for argument 'edge_index' but instead found type 'Union[Tensor, __torch__.torch_sparse.tensor.SparseTensor]'.\n\nThe original call is:\n  File \"/tmp/bindera_pyg/tmpd9y4phyc.py\", line 238\n        # type: (Tensor, Tensor, Adj) -> Tensor\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n              ~~~~~~~~~~~~~~ <--- HERE\n        out = self.lin_g(out)\n        return x + out\n"
     ]
    }
   ],
   "source": [
    "t = '(Tensor, Tensor, Adj) -> Tensor'\n",
    "jit = torch.jit.script(conv.jittable(t))\n",
    "assert jit(x, x, edge_index).tolist() == out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nArguments for call are not valid.\nThe following variants are available:\n  \n  propagate__0(__torch__.PointGNNConvJittable_6f899b.PointGNNConvJittable_6f899b self, Tensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Argument size not provided.\n  \n  propagate__1(__torch__.PointGNNConvJittable_6f899b.PointGNNConvJittable_6f899b self, __torch__.torch_sparse.tensor.SparseTensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type '__torch__.torch_sparse.tensor.SparseTensor (of Python compilation unit at: 0x5028480)' for argument 'edge_index' but instead found type 'Tensor'.\n\nThe original call is:\n  File \"/tmp/bindera_pyg/tmp1pwnyawp.py\", line 238\n        # type: (Tensor, Tensor, Tensor) -> Tensor\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n              ~~~~~~~~~~~~~~ <--- HERE\n        out = self.lin_g(out)\n        return x + out\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1039835/3540992812.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(Tensor, Tensor, Tensor) -> Tensor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mjit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjittable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         return torch.jit._recursive.create_script_module(\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nArguments for call are not valid.\nThe following variants are available:\n  \n  propagate__0(__torch__.PointGNNConvJittable_6f899b.PointGNNConvJittable_6f899b self, Tensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Argument size not provided.\n  \n  propagate__1(__torch__.PointGNNConvJittable_6f899b.PointGNNConvJittable_6f899b self, __torch__.torch_sparse.tensor.SparseTensor edge_index, Tensor x, Tensor pos, (int, int)? size) -> Tensor:\n  Expected a value of type '__torch__.torch_sparse.tensor.SparseTensor (of Python compilation unit at: 0x5028480)' for argument 'edge_index' but instead found type 'Tensor'.\n\nThe original call is:\n  File \"/tmp/bindera_pyg/tmp1pwnyawp.py\", line 238\n        # type: (Tensor, Tensor, Tensor) -> Tensor\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n              ~~~~~~~~~~~~~~ <--- HERE\n        out = self.lin_g(out)\n        return x + out\n"
     ]
    }
   ],
   "source": [
    "from src.adversarial_attacks_on_feature_dependent_graphs.baselines import PointGNNConv\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(6, 3)\n",
    "edge_index = torch.tensor([[0, 1, 1, 1, 2, 5], [1, 2, 3, 4, 3, 4]])\n",
    "row, col = edge_index\n",
    "adj = SparseTensor(row=row, col=col, sparse_sizes=(6, 6))\n",
    "MLP_h = MLP([3, 64, 3])\n",
    "MLP_f = MLP([6, 64, 3])\n",
    "MLP_g = MLP([3, 64, 3])\n",
    "\n",
    "conv = PointGNNConv(state_channels=3, MLP_h=MLP_h, MLP_f=MLP_f, MLP_g=MLP_g)\n",
    "assert conv.__repr__() == 'PointGNNConv(3, lin_h=MLP(3, 64, 3), lin_f=MLP(6, 64, 3),lin_g=MLP(3, 64, 3))'\n",
    "out = conv(x, x, edge_index)\n",
    "\n",
    "assert out.size() == (6, 3)\n",
    "assert torch.allclose(conv(x, x, adj.t()), out, atol=1e-6)\n",
    "\n",
    "if True:\n",
    "    t = '(Tensor, Tensor, Tensor) -> Tensor'\n",
    "    jit = torch.jit.script(conv.jittable(t))\n",
    "    assert jit(x, x, edge_index).tolist() == out.tolist()\n",
    "\n",
    "    t = '(Tensor, Tensor, SparseTensor) -> Tensor'\n",
    "    jit = torch.jit.script(conv.jittable(t))\n",
    "    assert torch.allclose(jit(x, x, adj.t()), out, atol=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.adversarial_attacks_on_feature_dependent_graphs.baselines import PointGNNConv\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(6, 3)\n",
    "edge_index = torch.tensor([[0, 1, 1, 1, 2, 5], [1, 2, 3, 4, 3, 4]])\n",
    "row, col = edge_index\n",
    "adj = SparseTensor(row=row, col=col, sparse_sizes=(6, 6))\n",
    "MLP_h = MLP([3, 64, 3])\n",
    "MLP_f = MLP([6, 64, 3])\n",
    "MLP_g = MLP([3, 64, 3])\n",
    "\n",
    "conv = PointGNNConv(state_channels=3, MLP_h=MLP_h, MLP_f=MLP_f, MLP_g=MLP_g)\n",
    "assert conv.__repr__() == 'PointGNNConv(3, lin_h=MLP(3, 64, 3),' \\\n",
    "                        ' lin_f=MLP(6, 64, 3),lin_g=MLP(3, 64, 3))'\n",
    "#string = 'PointGNNConv(3, lin_h=MLP(3, 64, 3), lin_f=MLP(6, 64, 3),lin_g=MLP(3, 64, 3))'\n",
    "#assert conv.__repr__() == 'PointGNNConv(3, lin_h=MLP(3, 64, 3), lin_f=MLP(6, 64, 3),lin_g=MLP(3, 64, 3))'\n",
    "out = conv(x, x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.adversarial_attacks_on_feature_dependent_graphs.baselines failed: Traceback (most recent call last):\n",
      "  File \"/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/nfs/homedirs/bindera/Adversarial Attacks on Feature-Dependent Graphs/src/adversarial_attacks_on_feature_dependent_graphs/baselines.py\", line 111, in <module>\n",
      "    from torch_geometric.nn import PointGNNConv, MLP\n",
      "ImportError: cannot import name 'PointGNNConv' from 'torch_geometric.nn' (/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch_geometric/nn/__init__.py)\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nUnknown type name 'Adj':\n  File \"/nfs/homedirs/bindera/Adversarial Attacks on Feature-Dependent Graphs/src/adversarial_attacks_on_feature_dependent_graphs/baselines.py\", line 90\n    def forward(self, x: Tensor, pos: Tensor, edge_index: Adj) -> Tensor:\n                                                          ~~~ <--- HERE\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n'PointGNNConvJittable_24da9e.message' is being compiled since it was called from 'PointGNNConvJittable_24da9e.propagate__0'\n  File \"/tmp/bindera_pyg/tmpyq5ljxes.py\", line 217\n    \n        kwargs = self.__collect__(edge_index, the_size, in_kwargs)\n        out = self.message(pos_i=kwargs.pos_i, pos_j=kwargs.pos_j, x_i=kwargs.x_i, x_j=kwargs.x_j)\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        out = self.aggregate(out, ptr=kwargs.ptr, dim_size=kwargs.dim_size, index=kwargs.index)\n        return self.update(out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1039835/1537224788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(Tensor, Tensor) -> Tensor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjittable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# t = '(Tensor, SparseTensor, OptTensor) -> Tensor'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_script.py\u001b[0m in \u001b[0;36mscript\u001b[0;34m(obj, optimize, _frames_up, _rcb, example_inputs)\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_prepare_scriptable_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         return torch.jit._recursive.create_script_module(\n\u001b[0;32m-> 1287\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recursive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_methods_to_compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m         )\n\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module\u001b[0;34m(nn_module, stubs_fn, share_types, is_tracing)\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tracing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mAttributeTypeIsSupportedChecker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_script_module_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstubs_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_script_module_impl\u001b[0;34m(nn_module, concrete_type, stubs_fn)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;31m# Compile methods if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconcrete_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconcrete_type_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethods_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Create hooks after methods to ensure no name collisions between hooks and methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# If done before, hooks can overshadow methods that aren't exported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcompile_unbound_method\u001b[0;34m(concrete_type, fn)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# We don't want to call the hooks here since the graph that is calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# this function is not yet complete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mcreate_methods_and_properties_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_recursive.py\u001b[0m in \u001b[0;36mcreate_methods_and_properties_from_stubs\u001b[0;34m(concrete_type, method_stubs, property_stubs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mproperty_rcbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolution_callback\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproperty_stubs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0mconcrete_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_methods_and_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproperty_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproperty_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_rcbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_hooks_from_stubs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcrete_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_stubs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_hook_stubs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \nUnknown type name 'Adj':\n  File \"/nfs/homedirs/bindera/Adversarial Attacks on Feature-Dependent Graphs/src/adversarial_attacks_on_feature_dependent_graphs/baselines.py\", line 90\n    def forward(self, x: Tensor, pos: Tensor, edge_index: Adj) -> Tensor:\n                                                          ~~~ <--- HERE\n        # propagate_type: (x: Tensor, pos: Tensor)\n        out = self.propagate(edge_index, x=x, pos=pos)\n'PointGNNConvJittable_24da9e.message' is being compiled since it was called from 'PointGNNConvJittable_24da9e.propagate__0'\n  File \"/tmp/bindera_pyg/tmpyq5ljxes.py\", line 217\n    \n        kwargs = self.__collect__(edge_index, the_size, in_kwargs)\n        out = self.message(pos_i=kwargs.pos_i, pos_j=kwargs.pos_j, x_i=kwargs.x_i, x_j=kwargs.x_j)\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n        out = self.aggregate(out, ptr=kwargs.ptr, dim_size=kwargs.dim_size, index=kwargs.index)\n        return self.update(out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = '(Tensor, Tensor) -> Tensor'\n",
    "jit = torch.jit.script(conv.jittable(t))\n",
    "assert jit(x, edge_index).tolist() == out.tolist()\n",
    "\n",
    "# t = '(Tensor, SparseTensor, OptTensor) -> Tensor'\n",
    "# jit = torch.jit.script(conv.jittable(t))\n",
    "# assert torch.allclose(jit(x, adj.t()), out, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4053704/3447052868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert conv(x, x, adj.t()).tolist() == out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def test_sum(a: Tensor,\n",
      "    b: Tensor) -> Tensor:\n",
      "  return torch.add(a, b)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/torch/jit/_script.py:1280: UserWarning: Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType to enable Profile-Directed Typing in TorchScript. Refer to https://github.com/Instagram/MonkeyType/blob/master/README.rst to install MonkeyType. \n",
      "  warnings.warn(\"Warning: monkeytype is not installed. Please install https://github.com/Instagram/MonkeyType \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "test_sum() Expected a value of type 'Tensor (inferred)' for argument 'a' but instead found type 'int'.\nInferred 'a' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 0\nValue: 20\nDeclaration: test_sum(Tensor a, Tensor b) -> Tensor\nCast error details: Unable to cast 20 to Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1039835/3998101174.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Call the function using the TorchScript interpreter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mscripted_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: test_sum() Expected a value of type 'Tensor (inferred)' for argument 'a' but instead found type 'int'.\nInferred 'a' to be of type 'Tensor' because it was not annotated with an explicit type.\nPosition: 0\nValue: 20\nDeclaration: test_sum(Tensor a, Tensor b) -> Tensor\nCast error details: Unable to cast 20 to Tensor"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def test_sum(a, b):\n",
    "    return a + b\n",
    "\n",
    "# Annotate the arguments to be int\n",
    "scripted_fn = torch.jit.script(test_sum, example_inputs=[(3, 4)])\n",
    "\n",
    "print(type(scripted_fn))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(scripted_fn.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "scripted_fn(20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7913013100624084, 0.038601651787757874, -0.1411139965057373],\n",
       " [-0.7865033745765686, 0.4582751393318176, -0.742428719997406],\n",
       " [1.0047038793563843, -1.337821125984192, 1.5362837314605713],\n",
       " [-0.29695242643356323, -0.15038949251174927, 0.4561692774295807],\n",
       " [0.010547250509262085, 0.21245476603507996, 0.4234809875488281],\n",
       " [0.7835968136787415, 0.7526127099990845, 1.9474248886108398]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x, x, adj.t()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.5826876163482666, -0.30090582370758057, -0.5688638091087341],\n",
       " [-0.5629196763038635, 0.1901358813047409, -1.791551113128662],\n",
       " [-1.0719306468963623, -0.5419655442237854, 2.1522042751312256],\n",
       " [-2.713207721710205, -2.304295778274536, 0.11807659268379211],\n",
       " [-0.32690030336380005, -0.8785462975502014, -0.6353766918182373],\n",
       " [2.14768385887146, 0.22164282202720642, 1.0005592107772827]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(x, x, adj.t()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.5826878547668457, -0.30090591311454773, -0.5688638091087341],\n",
       " [-0.5629197955131531, 0.19013582170009613, -1.791551113128662],\n",
       " [-1.0719306468963623, -0.5419654846191406, 2.1522042751312256],\n",
       " [-2.713207721710205, -2.3042960166931152, 0.1180766373872757],\n",
       " [-0.3269002437591553, -0.8785462975502014, -0.6353767514228821],\n",
       " [2.14768385887146, 0.22164276242256165, 1.0005593299865723]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pointgnn_conv():\n",
    "    x = torch.randn(6, 3)\n",
    "    edge_index = torch.tensor([[0, 1, 1, 1, 2, 5], [1, 2, 3, 4, 3, 4]])\n",
    "    row, col = edge_index\n",
    "    adj = SparseTensor(row=row, col=col, sparse_sizes=(6, 6))\n",
    "\n",
    "    conv = PointGNNConv(16, 32, num_stacks=8, num_layers=4)\n",
    "    # assert conv.__repr__() == 'ARMAConv(16, 32, num_stacks=8, num_layers=4)'\n",
    "    out = conv(x, edge_index)\n",
    "    assert out.size() == (4, 32)\n",
    "    assert conv(x, adj.t()).tolist() == out.tolist()\n",
    "\n",
    "    if is_full_test():\n",
    "        t = '(Tensor, Tensor, OptTensor) -> Tensor'\n",
    "        jit = torch.jit.script(conv.jittable(t))\n",
    "        assert jit(x, edge_index).tolist() == out.tolist()\n",
    "\n",
    "        t = '(Tensor, SparseTensor, OptTensor) -> Tensor'\n",
    "        jit = torch.jit.script(conv.jittable(t))\n",
    "        assert torch.allclose(jit(x, adj.t()), out, atol=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 16)\n",
    "edge_index = torch.tensor([[0, 0, 0, 1, 2, 3], [1, 2, 3, 0, 0, 0]])\n",
    "row, col = edge_index\n",
    "adj = SparseTensor(row=row, col=col, sparse_sizes=(4, 4))\n",
    "\n",
    "conv = ARMAConv(16, 32, num_stacks=8, num_layers=4)\n",
    "assert conv.__repr__() == 'ARMAConv(16, 32, num_stacks=8, num_layers=4)'\n",
    "out = conv(x, edge_index)\n",
    "assert out.size() == (4, 32)\n",
    "assert conv(x, adj.t()).tolist() == out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.jit.ScriptFunction'>\n",
      "def foo(x: Tensor,\n",
      "    y: Tensor) -> Tensor:\n",
      "  _0 = bool(torch.gt(torch.max(x), torch.max(y)))\n",
      "  if _0:\n",
      "    r = x\n",
      "  else:\n",
      "    r = y\n",
      "  return r\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.jit.script\n",
    "def foo(x, y):\n",
    "    if x.max() > y.max():\n",
    "        r = x\n",
    "    else:\n",
    "        r = y\n",
    "    return r\n",
    "\n",
    "print(type(foo))  # torch.jit.ScriptFunction\n",
    "\n",
    "# See the compiled graph as Python code\n",
    "print(foo.code)\n",
    "\n",
    "# Call the function using the TorchScript interpreter\n",
    "foo(torch.ones(2, 2), torch.ones(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import ClusterGCNConv\n",
    "\n",
    "x = torch.randn(4, 16)\n",
    "edge_index = torch.tensor([[0, 1, 2, 3], [0, 0, 1, 1]])\n",
    "row, col = edge_index\n",
    "adj = SparseTensor(row=row, col=col, sparse_sizes=(4, 4))\n",
    "\n",
    "conv = ClusterGCNConv(16, 32, diag_lambda=1.)\n",
    "assert conv.__repr__() == 'ClusterGCNConv(16, 32, diag_lambda=1.0)'\n",
    "out = conv(x, edge_index)\n",
    "assert out.size() == (4, 32)\n",
    "assert torch.allclose(conv(x, adj.t()), out, atol=1e-5)\n",
    "\n",
    "if True:\n",
    "    t = '(Tensor, Tensor) -> Tensor'\n",
    "    jit = torch.jit.script(conv.jittable(t))\n",
    "    assert jit(x, edge_index).tolist() == out.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=ClusterGCNConvJittable_fd4d57\n",
       "  (aggr_module): RecursiveScriptModule(original_name=SumAggregation)\n",
       "  (lin_out): RecursiveScriptModule(original_name=Linear)\n",
       "  (lin_root): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('test_torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5bc635c08695c038caab5ad03a90a71517b8fe0483ea60bcde3f3090b3b7f93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
