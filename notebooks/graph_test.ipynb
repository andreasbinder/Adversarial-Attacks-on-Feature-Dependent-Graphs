{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from src.adversarial_attacks_on_feature_dependent_graphs.data import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_train_1024pts_fps.dat'\n",
    "# x = torch.load(path)\n",
    "with open(path, 'rb') as f:\n",
    "    list_of_points, list_of_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/nfs/homedirs/bindera/Adversarial Attacks on Feature-Dependent Graphs/src/adversarial_attacks_on_feature_dependent_graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9843"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_of_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data is 9843\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_train_1024pts_fps.dat...\n",
      "The size of test data is 2468\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_test_1024pts_fps.dat...\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../../../shared/modelnet/modelnet40_normal_resampled'\n",
    "data_train, data_val, data_test = get_dataset(name = 'modelnet40', data_folder = data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor(dataset):\n",
    "    xs , ys = [], []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        xs.append(torch.tensor(x))\n",
    "        ys.append(torch.tensor(y))\n",
    "    \n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = to_tensor(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2468, 1024, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(39, dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([t,t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[1,1], [1,2], [4,5]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 493,   34,  126,  ..., 1003,  161,  484],\n",
       "        [   0,    0,    0,  ..., 1023, 1023, 1023]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import radius_graph\n",
    "\n",
    "# x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "# x = torch.Tensor([[1,1], [1,2], [4,5]])\n",
    "batch = torch.tensor([0, 1, 0])\n",
    "edge_index = radius_graph(x[0], r=1)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url, InMemoryDataset\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch\n",
    "from torch_geometric.nn import radius_graph\n",
    "\n",
    "\n",
    "\n",
    "class PointCloudDataset(InMemoryDataset):  # Dataset\n",
    "    def __init__(self, data_folder = '../../../shared/modelnet/modelnet40_normal_resampled', split = 'train', transform=None, pre_transform=None, pre_filter=None):\n",
    "        super().__init__(None, transform, pre_transform, pre_filter)\n",
    "\n",
    "        subset = self.load(data_folder=data_folder, split=split)\n",
    "\n",
    "        self.data_list = self.extract_data_from_dict(subset)\n",
    "\n",
    "        \n",
    "    def load(self, data_folder, split):\n",
    "        \n",
    "        data_train, data_val, data_test = get_dataset(name = 'modelnet40', data_folder = data_folder)\n",
    "\n",
    "        if split == 'train':\n",
    "            return data_train\n",
    "        elif split == 'val':\n",
    "            return data_val\n",
    "        elif split == 'test':\n",
    "            return data_test\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def to_tensor(self, dataset):\n",
    "        xs , ys = [], []\n",
    "\n",
    "        for x, y in dataset:\n",
    "            xs.append(torch.tensor(x))\n",
    "            ys.append(torch.tensor(y))\n",
    "        \n",
    "        return torch.stack(xs), torch.stack(ys)\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = self.data_list[idx]\n",
    "        return data\n",
    "\n",
    "    def extract_data_from_dict(self, subset):\n",
    "        \n",
    "        # subset = self.to_tensor(subset)\n",
    "\n",
    "        list_of_data_objects = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for x, y in subset:\n",
    "          \n",
    "            x = torch.tensor(x)\n",
    "\n",
    "            # x = torch.Tensor([[-1, -1], [-1, 1], [1, -1], [1, 1]])\n",
    "            # x = torch.Tensor([[1,1], [1,2], [4,5]])\n",
    "            \n",
    "            edge_index = radius_graph(x=x, r=1)\n",
    "            data = Data(x = x, \n",
    "                        edge_index = edge_index.t().contiguous(), \n",
    "                        y = torch.tensor([y], dtype=torch.long))\n",
    "\n",
    "            list_of_data_objects.append(data)\n",
    "\n",
    "        return list_of_data_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data is 9843\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_train_1024pts_fps.dat...\n",
      "The size of test data is 2468\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_test_1024pts_fps.dat...\n"
     ]
    }
   ],
   "source": [
    "dataset = PointCloudDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1024, 3], edge_index=[32768, 2], y=[1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/bindera/miniconda3/envs/test_torch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data is 9843\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_train_1024pts_fps.dat...\n",
      "The size of test data is 2468\n",
      "Load processed data from ../../../shared/modelnet/modelnet40_normal_resampled/modelnet40_test_1024pts_fps.dat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1968/1968 [01:01<00:00, 31.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.adversarial_attacks_on_feature_dependent_graphs.dataset import PointCloudDataset\n",
    "from src.adversarial_attacks_on_feature_dependent_graphs.data import *\n",
    "\n",
    "val_dataset = PointCloudDataset(split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/nfs/students/bindera/data/modelnet_pyg/val_dataset.pt'\n",
    "torch.save(val_dataset, path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.15 ('test_torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5bc635c08695c038caab5ad03a90a71517b8fe0483ea60bcde3f3090b3b7f93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
